{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "respnse: b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n<feed xmlns=\"http://www.w3.org/2005/Atom\">\\n  <link href=\"http://arxiv.org/api/query?search_query%3Dall%3ALLM%20Recommend%26id_list%3D%26start%3D0%26max_results%3D5\" rel=\"self\" type=\"application/atom+xml\"/>\\n  <title type=\"html\">ArXiv Query: search_query=all:LLM Recommend&amp;id_list=&amp;start=0&amp;max_results=5</title>\\n  <id>http://arxiv.org/api/ohH+G+JroC1dnlYVAHDciywx8yY</id>\\n  <updated>2024-06-18T00:00:00-04:00</updated>\\n  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">31739</opensearch:totalResults>\\n  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\\n  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">5</opensearch:itemsPerPage>\\n  <entry>\\n    <id>http://arxiv.org/abs/2312.13557v1</id>\\n    <updated>2023-12-21T03:50:09Z</updated>\\n    <published>2023-12-21T03:50:09Z</published>\\n    <title>Empowering Few-Shot Recommender Systems with Large Language Models --\\n  Enhanced Representations</title>\\n    <summary>  Recommender systems utilizing explicit feedback have witnessed significant\\nadvancements and widespread applications over the past years. However,\\ngenerating recommendations in few-shot scenarios remains a persistent\\nchallenge. Recently, large language models (LLMs) have emerged as a promising\\nsolution for addressing natural language processing (NLP) tasks, thereby\\noffering novel insights into tackling the few-shot scenarios encountered by\\nexplicit feedback-based recommender systems. To bridge recommender systems and\\nLLMs, we devise a prompting template that generates user and item\\nrepresentations based on explicit feedback. Subsequently, we integrate these\\nLLM-processed representations into various recommendation models to evaluate\\ntheir significance across diverse recommendation tasks. Our ablation\\nexperiments and case study analysis collectively demonstrate the effectiveness\\nof LLMs in processing explicit feedback, highlighting that LLMs equipped with\\ngenerative and logical reasoning capabilities can effectively serve as a\\ncomponent of recommender systems to enhance their performance in few-shot\\nscenarios. Furthermore, the broad adaptability of LLMs augments the\\ngeneralization potential of recommender models, despite certain inherent\\nconstraints. We anticipate that our study can inspire researchers to delve\\ndeeper into the multifaceted dimensions of LLMs\\'s involvement in recommender\\nsystems and contribute to the advancement of the explicit feedback-based\\nrecommender systems field.\\n</summary>\\n    <author>\\n      <name>Zhoumeng Wang</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 pages</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2312.13557v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2312.13557v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2405.16127v1</id>\\n    <updated>2024-05-25T08:36:15Z</updated>\\n    <published>2024-05-25T08:36:15Z</published>\\n    <title>Finetuning Large Language Model for Personalized Ranking</title>\\n    <summary>  Large Language Models (LLMs) have demonstrated remarkable performance across\\nvarious domains, motivating researchers to investigate their potential use in\\nrecommendation systems. However, directly applying LLMs to recommendation tasks\\nhas proven challenging due to the significant disparity between the data used\\nfor pre-training LLMs and the specific requirements of recommendation tasks. In\\nthis study, we introduce Direct Multi-Preference Optimization (DMPO), a\\nstreamlined framework designed to bridge the gap and enhance the alignment of\\nLLMs for recommendation tasks. DMPO enhances the performance of LLM-based\\nrecommenders by simultaneously maximizing the probability of positive samples\\nand minimizing the probability of multiple negative samples. We conducted\\nexperimental evaluations to compare DMPO against traditional recommendation\\nmethods and other LLM-based recommendation approaches. The results demonstrate\\nthat DMPO significantly improves the recommendation capabilities of LLMs across\\nthree real-world public datasets in few-shot scenarios. Additionally, the\\nexperiments indicate that DMPO exhibits superior generalization ability in\\ncross-domain recommendations. A case study elucidates the reasons behind these\\nconsistent improvements and also underscores DMPO\\'s potential as an explainable\\nrecommendation system.\\n</summary>\\n    <author>\\n      <name>Zhuoxi Bai</name>\\n    </author>\\n    <author>\\n      <name>Ning Wu</name>\\n    </author>\\n    <author>\\n      <name>Fengyu Cai</name>\\n    </author>\\n    <author>\\n      <name>Xinyi Zhu</name>\\n    </author>\\n    <author>\\n      <name>Yun Xiong</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2405.16127v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2405.16127v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2405.12119v1</id>\\n    <updated>2024-05-20T15:37:55Z</updated>\\n    <published>2024-05-20T15:37:55Z</published>\\n    <title>Reindex-Then-Adapt: Improving Large Language Models for Conversational\\n  Recommendation</title>\\n    <summary>  Large language models (LLMs) are revolutionizing conversational recommender\\nsystems by adeptly indexing item content, understanding complex conversational\\ncontexts, and generating relevant item titles. However, controlling the\\ndistribution of recommended items remains a challenge. This leads to suboptimal\\nperformance due to the failure to capture rapidly changing data distributions,\\nsuch as item popularity, on targeted conversational recommendation platforms.\\nIn conversational recommendation, LLMs recommend items by generating the titles\\n(as multiple tokens) autoregressively, making it difficult to obtain and\\ncontrol the recommendations over all items. Thus, we propose a\\nReindex-Then-Adapt (RTA) framework, which converts multi-token item titles into\\nsingle tokens within LLMs, and then adjusts the probability distributions over\\nthese single-token item titles accordingly. The RTA framework marries the\\nbenefits of both LLMs and traditional recommender systems (RecSys):\\nunderstanding complex queries as LLMs do; while efficiently controlling the\\nrecommended item distributions in conversational recommendations as traditional\\nRecSys do. Our framework demonstrates improved accuracy metrics across three\\ndifferent conversational recommendation datasets and two adaptation settings\\n</summary>\\n    <author>\\n      <name>Zhankui He</name>\\n    </author>\\n    <author>\\n      <name>Zhouhang Xie</name>\\n    </author>\\n    <author>\\n      <name>Harald Steck</name>\\n    </author>\\n    <author>\\n      <name>Dawen Liang</name>\\n    </author>\\n    <author>\\n      <name>Rahul Jha</name>\\n    </author>\\n    <author>\\n      <name>Nathan Kallus</name>\\n    </author>\\n    <author>\\n      <name>Julian McAuley</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2405.12119v1\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2405.12119v1\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2307.00457v2</id>\\n    <updated>2023-07-04T20:04:58Z</updated>\\n    <published>2023-07-02T02:37:07Z</published>\\n    <title>GenRec: Large Language Model for Generative Recommendation</title>\\n    <summary>  In recent years, large language models (LLM) have emerged as powerful tools\\nfor diverse natural language processing tasks. However, their potential for\\nrecommender systems under the generative recommendation paradigm remains\\nrelatively unexplored. This paper presents an innovative approach to\\nrecommendation systems using large language models (LLMs) based on text data.\\nIn this paper, we present a novel LLM for generative recommendation (GenRec)\\nthat utilized the expressive power of LLM to directly generate the target item\\nto recommend, rather than calculating ranking score for each candidate item one\\nby one as in traditional discriminative recommendation. GenRec uses LLM\\'s\\nunderstanding ability to interpret context, learn user preferences, and\\ngenerate relevant recommendation. Our proposed approach leverages the vast\\nknowledge encoded in large language models to accomplish recommendation tasks.\\nWe first we formulate specialized prompts to enhance the ability of LLM to\\ncomprehend recommendation tasks. Subsequently, we use these prompts to\\nfine-tune the LLaMA backbone LLM on a dataset of user-item interactions,\\nrepresented by textual data, to capture user preferences and item\\ncharacteristics. Our research underscores the potential of LLM-based generative\\nrecommendation in revolutionizing the domain of recommendation systems and\\noffers a foundational framework for future explorations in this field. We\\nconduct extensive experiments on benchmark datasets, and the experiments shows\\nthat our GenRec has significant better results on large dataset.\\n</summary>\\n    <author>\\n      <name>Jianchao Ji</name>\\n    </author>\\n    <author>\\n      <name>Zelong Li</name>\\n    </author>\\n    <author>\\n      <name>Shuyuan Xu</name>\\n    </author>\\n    <author>\\n      <name>Wenyue Hua</name>\\n    </author>\\n    <author>\\n      <name>Yingqiang Ge</name>\\n    </author>\\n    <author>\\n      <name>Juntao Tan</name>\\n    </author>\\n    <author>\\n      <name>Yongfeng Zhang</name>\\n    </author>\\n    <link href=\"http://arxiv.org/abs/2307.00457v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2307.00457v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.LG\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n  <entry>\\n    <id>http://arxiv.org/abs/2309.01157v2</id>\\n    <updated>2024-03-23T17:05:42Z</updated>\\n    <published>2023-09-03T12:33:47Z</published>\\n    <title>Large Language Models for Generative Recommendation: A Survey and\\n  Visionary Discussions</title>\\n    <summary>  Large language models (LLM) not only have revolutionized the field of natural\\nlanguage processing (NLP) but also have the potential to reshape many other\\nfields, e.g., recommender systems (RS). However, most of the related work\\ntreats an LLM as a component of the conventional recommendation pipeline (e.g.,\\nas a feature extractor), which may not be able to fully leverage the generative\\npower of LLM. Instead of separating the recommendation process into multiple\\nstages, such as score computation and re-ranking, this process can be\\nsimplified to one stage with LLM: directly generating recommendations from the\\ncomplete pool of items. This survey reviews the progress, methods, and future\\ndirections of LLM-based generative recommendation by examining three questions:\\n1) What generative recommendation is, 2) Why RS should advance to generative\\nrecommendation, and 3) How to implement LLM-based generative recommendation for\\nvarious RS tasks. We hope that this survey can provide the context and guidance\\nneeded to explore this interesting and emerging topic.\\n</summary>\\n    <author>\\n      <name>Lei Li</name>\\n    </author>\\n    <author>\\n      <name>Yongfeng Zhang</name>\\n    </author>\\n    <author>\\n      <name>Dugang Liu</name>\\n    </author>\\n    <author>\\n      <name>Li Chen</name>\\n    </author>\\n    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Published as a conference paper at LREC-COLING 2024</arxiv:comment>\\n    <link href=\"http://arxiv.org/abs/2309.01157v2\" rel=\"alternate\" type=\"text/html\"/>\\n    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2309.01157v2\" rel=\"related\" type=\"application/pdf\"/>\\n    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.IR\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n    <category term=\"cs.CL\" scheme=\"http://arxiv.org/schemas/atom\"/>\\n  </entry>\\n</feed>\\n'\n",
      "Feed title: ArXiv Query: search_query=all:LLM Recommend&amp;id_list=&amp;start=0&amp;max_results=5\n",
      "Feed last updated: 2024-06-18T00:00:00-04:00\n",
      "totalResults for this query: 31739\n",
      "itemsPerPage for this query: 5\n",
      "startIndex for this query: 0\n",
      "e-print metadata\n",
      "arxiv-id: 2312.13557v1\n",
      "Published: 2023-12-21T03:50:09Z\n",
      "Title:  Empowering Few-Shot Recommender Systems with Large Language Models --\n",
      "  Enhanced Representations\n",
      "Last Author:  Zhoumeng Wang\n",
      "Authors:  Zhoumeng Wang\n",
      "abs page link: http://arxiv.org/abs/2312.13557v1\n",
      "pdf link: http://arxiv.org/pdf/2312.13557v1\n",
      "Journal reference: No journal ref found\n",
      "Comments: 10 pages\n",
      "Primary Category: cs.IR\n",
      "All Categories: cs.IR, cs.AI\n",
      "Abstract: Recommender systems utilizing explicit feedback have witnessed significant\n",
      "advancements and widespread applications over the past years. However,\n",
      "generating recommendations in few-shot scenarios remains a persistent\n",
      "challenge. Recently, large language models (LLMs) have emerged as a promising\n",
      "solution for addressing natural language processing (NLP) tasks, thereby\n",
      "offering novel insights into tackling the few-shot scenarios encountered by\n",
      "explicit feedback-based recommender systems. To bridge recommender systems and\n",
      "LLMs, we devise a prompting template that generates user and item\n",
      "representations based on explicit feedback. Subsequently, we integrate these\n",
      "LLM-processed representations into various recommendation models to evaluate\n",
      "their significance across diverse recommendation tasks. Our ablation\n",
      "experiments and case study analysis collectively demonstrate the effectiveness\n",
      "of LLMs in processing explicit feedback, highlighting that LLMs equipped with\n",
      "generative and logical reasoning capabilities can effectively serve as a\n",
      "component of recommender systems to enhance their performance in few-shot\n",
      "scenarios. Furthermore, the broad adaptability of LLMs augments the\n",
      "generalization potential of recommender models, despite certain inherent\n",
      "constraints. We anticipate that our study can inspire researchers to delve\n",
      "deeper into the multifaceted dimensions of LLMs's involvement in recommender\n",
      "systems and contribute to the advancement of the explicit feedback-based\n",
      "recommender systems field.\n",
      "e-print metadata\n",
      "arxiv-id: 2405.16127v1\n",
      "Published: 2024-05-25T08:36:15Z\n",
      "Title:  Finetuning Large Language Model for Personalized Ranking\n",
      "Last Author:  Yun Xiong\n",
      "Authors:  Zhuoxi Bai, Ning Wu, Fengyu Cai, Xinyi Zhu, Yun Xiong\n",
      "abs page link: http://arxiv.org/abs/2405.16127v1\n",
      "pdf link: http://arxiv.org/pdf/2405.16127v1\n",
      "Journal reference: No journal ref found\n",
      "Comments: No comment found\n",
      "Primary Category: cs.IR\n",
      "All Categories: cs.IR\n",
      "Abstract: Large Language Models (LLMs) have demonstrated remarkable performance across\n",
      "various domains, motivating researchers to investigate their potential use in\n",
      "recommendation systems. However, directly applying LLMs to recommendation tasks\n",
      "has proven challenging due to the significant disparity between the data used\n",
      "for pre-training LLMs and the specific requirements of recommendation tasks. In\n",
      "this study, we introduce Direct Multi-Preference Optimization (DMPO), a\n",
      "streamlined framework designed to bridge the gap and enhance the alignment of\n",
      "LLMs for recommendation tasks. DMPO enhances the performance of LLM-based\n",
      "recommenders by simultaneously maximizing the probability of positive samples\n",
      "and minimizing the probability of multiple negative samples. We conducted\n",
      "experimental evaluations to compare DMPO against traditional recommendation\n",
      "methods and other LLM-based recommendation approaches. The results demonstrate\n",
      "that DMPO significantly improves the recommendation capabilities of LLMs across\n",
      "three real-world public datasets in few-shot scenarios. Additionally, the\n",
      "experiments indicate that DMPO exhibits superior generalization ability in\n",
      "cross-domain recommendations. A case study elucidates the reasons behind these\n",
      "consistent improvements and also underscores DMPO's potential as an explainable\n",
      "recommendation system.\n",
      "e-print metadata\n",
      "arxiv-id: 2405.12119v1\n",
      "Published: 2024-05-20T15:37:55Z\n",
      "Title:  Reindex-Then-Adapt: Improving Large Language Models for Conversational\n",
      "  Recommendation\n",
      "Last Author:  Julian McAuley\n",
      "Authors:  Zhankui He, Zhouhang Xie, Harald Steck, Dawen Liang, Rahul Jha, Nathan Kallus, Julian McAuley\n",
      "abs page link: http://arxiv.org/abs/2405.12119v1\n",
      "pdf link: http://arxiv.org/pdf/2405.12119v1\n",
      "Journal reference: No journal ref found\n",
      "Comments: No comment found\n",
      "Primary Category: cs.IR\n",
      "All Categories: cs.IR, cs.AI, cs.CL\n",
      "Abstract: Large language models (LLMs) are revolutionizing conversational recommender\n",
      "systems by adeptly indexing item content, understanding complex conversational\n",
      "contexts, and generating relevant item titles. However, controlling the\n",
      "distribution of recommended items remains a challenge. This leads to suboptimal\n",
      "performance due to the failure to capture rapidly changing data distributions,\n",
      "such as item popularity, on targeted conversational recommendation platforms.\n",
      "In conversational recommendation, LLMs recommend items by generating the titles\n",
      "(as multiple tokens) autoregressively, making it difficult to obtain and\n",
      "control the recommendations over all items. Thus, we propose a\n",
      "Reindex-Then-Adapt (RTA) framework, which converts multi-token item titles into\n",
      "single tokens within LLMs, and then adjusts the probability distributions over\n",
      "these single-token item titles accordingly. The RTA framework marries the\n",
      "benefits of both LLMs and traditional recommender systems (RecSys):\n",
      "understanding complex queries as LLMs do; while efficiently controlling the\n",
      "recommended item distributions in conversational recommendations as traditional\n",
      "RecSys do. Our framework demonstrates improved accuracy metrics across three\n",
      "different conversational recommendation datasets and two adaptation settings\n",
      "e-print metadata\n",
      "arxiv-id: 2307.00457v2\n",
      "Published: 2023-07-02T02:37:07Z\n",
      "Title:  GenRec: Large Language Model for Generative Recommendation\n",
      "Last Author:  Yongfeng Zhang\n",
      "Authors:  Jianchao Ji, Zelong Li, Shuyuan Xu, Wenyue Hua, Yingqiang Ge, Juntao Tan, Yongfeng Zhang\n",
      "abs page link: http://arxiv.org/abs/2307.00457v2\n",
      "pdf link: http://arxiv.org/pdf/2307.00457v2\n",
      "Journal reference: No journal ref found\n",
      "Comments: No comment found\n",
      "Primary Category: cs.IR\n",
      "All Categories: cs.IR, cs.AI, cs.CL, cs.LG\n",
      "Abstract: In recent years, large language models (LLM) have emerged as powerful tools\n",
      "for diverse natural language processing tasks. However, their potential for\n",
      "recommender systems under the generative recommendation paradigm remains\n",
      "relatively unexplored. This paper presents an innovative approach to\n",
      "recommendation systems using large language models (LLMs) based on text data.\n",
      "In this paper, we present a novel LLM for generative recommendation (GenRec)\n",
      "that utilized the expressive power of LLM to directly generate the target item\n",
      "to recommend, rather than calculating ranking score for each candidate item one\n",
      "by one as in traditional discriminative recommendation. GenRec uses LLM's\n",
      "understanding ability to interpret context, learn user preferences, and\n",
      "generate relevant recommendation. Our proposed approach leverages the vast\n",
      "knowledge encoded in large language models to accomplish recommendation tasks.\n",
      "We first we formulate specialized prompts to enhance the ability of LLM to\n",
      "comprehend recommendation tasks. Subsequently, we use these prompts to\n",
      "fine-tune the LLaMA backbone LLM on a dataset of user-item interactions,\n",
      "represented by textual data, to capture user preferences and item\n",
      "characteristics. Our research underscores the potential of LLM-based generative\n",
      "recommendation in revolutionizing the domain of recommendation systems and\n",
      "offers a foundational framework for future explorations in this field. We\n",
      "conduct extensive experiments on benchmark datasets, and the experiments shows\n",
      "that our GenRec has significant better results on large dataset.\n",
      "e-print metadata\n",
      "arxiv-id: 2309.01157v2\n",
      "Published: 2023-09-03T12:33:47Z\n",
      "Title:  Large Language Models for Generative Recommendation: A Survey and\n",
      "  Visionary Discussions\n",
      "Last Author:  Li Chen\n",
      "Authors:  Lei Li, Yongfeng Zhang, Dugang Liu, Li Chen\n",
      "abs page link: http://arxiv.org/abs/2309.01157v2\n",
      "pdf link: http://arxiv.org/pdf/2309.01157v2\n",
      "Journal reference: No journal ref found\n",
      "Comments: Published as a conference paper at LREC-COLING 2024\n",
      "Primary Category: cs.IR\n",
      "All Categories: cs.IR, cs.AI, cs.CL\n",
      "Abstract: Large language models (LLM) not only have revolutionized the field of natural\n",
      "language processing (NLP) but also have the potential to reshape many other\n",
      "fields, e.g., recommender systems (RS). However, most of the related work\n",
      "treats an LLM as a component of the conventional recommendation pipeline (e.g.,\n",
      "as a feature extractor), which may not be able to fully leverage the generative\n",
      "power of LLM. Instead of separating the recommendation process into multiple\n",
      "stages, such as score computation and re-ranking, this process can be\n",
      "simplified to one stage with LLM: directly generating recommendations from the\n",
      "complete pool of items. This survey reviews the progress, methods, and future\n",
      "directions of LLM-based generative recommendation by examining three questions:\n",
      "1) What generative recommendation is, 2) Why RS should advance to generative\n",
      "recommendation, and 3) How to implement LLM-based generative recommendation for\n",
      "various RS tasks. We hope that this survey can provide the context and guidance\n",
      "needed to explore this interesting and emerging topic.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "python_arXiv_parsing_example.py\n",
    "\n",
    "This sample script illustrates a basic arXiv api call\n",
    "followed by parsing of the results using the\n",
    "feedparser python module.\n",
    "\n",
    "Please see the documentation at\n",
    "http://export.arxiv.org/api_help/docs/user-manual.html\n",
    "for more information, or email the arXiv api\n",
    "mailing list at arxiv-api@googlegroups.com.\n",
    "\n",
    "urllib is included in the standard python library.\n",
    "feedparser can be downloaded from http://feedparser.org/ .\n",
    "\n",
    "Author: Julius B. Lucks\n",
    "\n",
    "This is free software.  Feel free to do what you want\n",
    "with it, but please play nice with the arXiv API!\n",
    "\"\"\"\n",
    "\n",
    "import urllib.request\n",
    "import feedparser\n",
    "\n",
    "# Base api query url\n",
    "base_url = 'http://export.arxiv.org/api/query?';\n",
    "# https://arxiv.org/search/?query=LLM+Recommend&searchtype=all&source=header\n",
    "# Search parameters\n",
    "search_query = 'all:LLM+Recommend'  # search for electron in all fields\n",
    "start = 0  # retreive the first 5 results\n",
    "max_results = 5\n",
    "\n",
    "query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
    "                                                     start,\n",
    "                                                     max_results)\n",
    "\n",
    "# Opensearch metadata such as totalResults, startIndex,\n",
    "# and itemsPerPage live in the opensearch namespase.\n",
    "# Some entry metadata lives in the arXiv namespace.\n",
    "# This is a hack to expose both of these namespaces in\n",
    "# feedparser v4.1\n",
    "# feedparser._FeedParserMixin.namespaces['http://a9.com/-/spec/opensearch/1.1/'] = 'opensearch'\n",
    "# feedparser._FeedParserMixin.namespaces['http://arxiv.org/schemas/atom'] = 'arxiv'\n",
    "\n",
    "# perform a GET request using the base_url and query\n",
    "response = urllib.request.urlopen(base_url + query).read()\n",
    "print(\"respnse:\",response)\n",
    "# parse the response using feedparser\n",
    "feed = feedparser.parse(response)\n",
    "\n",
    "# print out feed information\n",
    "print('Feed title: %s' % feed.feed.title)\n",
    "print('Feed last updated: %s' % feed.feed.updated)\n",
    "\n",
    "# print opensearch metadata\n",
    "print('totalResults for this query: %s' % feed.feed.opensearch_totalresults)\n",
    "\n",
    "print('itemsPerPage for this query: %s' % feed.feed.opensearch_itemsperpage)\n",
    "\n",
    "print('startIndex for this query: %s' % feed.feed.opensearch_startindex)\n",
    "\n",
    "\n",
    "# Run through each entry, and print out information\n",
    "for entry in feed.entries:\n",
    "    print('e-print metadata')\n",
    "\n",
    "    print('arxiv-id: %s' % entry.id.split('/abs/')[-1])\n",
    "\n",
    "    print('Published: %s' % entry.published)\n",
    "\n",
    "    print('Title:  %s' % entry.title)\n",
    "\n",
    "\n",
    "    # feedparser v4.1 only grabs the first author\n",
    "    author_string = entry.author\n",
    "\n",
    "    # grab the affiliation in <arxiv:affiliation> if present\n",
    "    # - this will only grab the first affiliation encountered\n",
    "    #   (the first affiliation for the first author)\n",
    "    # Please email the list with a way to get all of this information!\n",
    "    try:\n",
    "        author_string += ' (%s)' % entry.arxiv_affiliation\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    print('Last Author:  %s' % author_string)\n",
    "\n",
    "\n",
    "    # feedparser v5.0.1 correctly handles multiple authors, print them all\n",
    "    try:\n",
    "        print('Authors:  %s' % ', '.join(author.name for author in entry.authors))\n",
    "\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "    # get the links to the abs page and pdf for this e-print\n",
    "    for link in entry.links:\n",
    "        if link.rel == 'alternate':\n",
    "            print('abs page link: %s' % link.href)\n",
    "\n",
    "        elif link.title == 'pdf':\n",
    "            print('pdf link: %s' % link.href)\n",
    "\n",
    "\n",
    "    # The journal reference, comments and primary_category sections live under\n",
    "    # the arxiv namespace\n",
    "    try:\n",
    "        journal_ref = entry.arxiv_journal_ref\n",
    "    except AttributeError:\n",
    "        journal_ref = 'No journal ref found'\n",
    "    print('Journal reference: %s' % journal_ref)\n",
    "\n",
    "\n",
    "    try:\n",
    "        comment = entry.arxiv_comment\n",
    "    except AttributeError:\n",
    "        comment = 'No comment found'\n",
    "    print('Comments: %s' % comment)\n",
    "\n",
    "\n",
    "    # Since the <arxiv:primary_category> element has no data, only\n",
    "    # attributes, feedparser does not store anything inside\n",
    "    # entry.arxiv_primary_category\n",
    "    # This is a dirty hack to get the primary_category, just take the\n",
    "    # first element in entry.tags.  If anyone knows a better way to do\n",
    "    # this, please email the list!\n",
    "    print('Primary Category: %s' % entry.tags[0]['term'])\n",
    "\n",
    "\n",
    "    # Lets get all the categories\n",
    "    all_categories = [t['term'] for t in entry.tags]\n",
    "    print('All Categories: %s' % (', ').join(all_categories))\n",
    "\n",
    "\n",
    "    # The abstract is in the <summary> element\n",
    "    print('Abstract: %s' % entry.summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Search_param(str):\n",
    "    \"\"\"\n",
    "    搜索参数管理类，用于拼接在baseurl之后\n",
    "\n",
    "    可以由generate方法encode生成初次检索所需的URL后缀\n",
    "    例如：”?term=alzheimer%27s+disease“\n",
    "    可以附加一些调整网页的属性\n",
    "\n",
    "    TODO: 按日期搜索，\n",
    "    2020.1.1 - 2020.1.31: \n",
    "    https://pubmed.ncbi.nlm.nih.gov/?term=computer+science&filter=dates.2020%2F1%2F1-2020%2F1%2F31\n",
    "\n",
    "    2024.5.1 - 2024.5.31\n",
    "    https://pubmed.ncbi.nlm.nih.gov/?term=computer+science&filter=dates.2024%2F5%2F1-2024%2F5%2F31\n",
    "    \"\"\"\n",
    "    def __init__(self, keywords:str):\n",
    "        self.search_keywords = {}\n",
    "        self.search_keywords['term'] = keywords.strip()\n",
    "\n",
    "    def gen_search_param(self) -> str:\n",
    "        # encode url生成request需要的url\n",
    "        return urllib.parse.urlencode(self.search_keywords)\n",
    "\n",
    "    def specify_web_size(self, size: int):\n",
    "        # 调整 搜索页面的大小\n",
    "        self.search_keywords['size'] = size\n",
    "\n",
    "    def specify_any_param(self, key: str, value):\n",
    "        \"\"\"\n",
    "        针对任意参数进行调整, 需要提供合适的键值对，默认不存在\n",
    "        目前观察到的有：sort(date, pubdate, fauth, jour), sort_order(asc) 更多参数请查看pubmed的搜索URL\n",
    "        :param key: url链接需要添加的键\n",
    "        :param value: url链接中键对应的值\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.search_keywords[key] = value\n",
    "\n",
    "def scrawl_from_arxiv(keywords: str = None):\n",
    "    base_url = 'http://export.arxiv.org/api/query?'\n",
    "    param = Search_param(keywords)\n",
    "\n",
    "    search_query = param.gen_search_param()\n",
    "    \n",
    "    start = 0  # retreive the first 5 results\n",
    "    max_results = 5\n",
    "\n",
    "    query = 'search_query=%s&start=%i&max_results=%i' % (search_query,\n",
    "                                                     start,\n",
    "                                                     max_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
